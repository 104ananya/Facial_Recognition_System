{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI - FACIAL RECOGNITION SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Background Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to set the background image\n",
    "def set_background_image(event=None):\n",
    "    # Get the current window size\n",
    "    window_width = window.winfo_width()\n",
    "    window_height = window.winfo_height()\n",
    "\n",
    "    # Load the image and resize it to fit the window\n",
    "    bg_image = Image.open(\"bgimg.jpg\")  # Replace with your image file\n",
    "    bg_image = bg_image.resize((window_width, window_height), Image.LANCZOS)\n",
    "    bg_image = ImageTk.PhotoImage(bg_image)\n",
    "\n",
    "    bg_label.configure(image=bg_image)\n",
    "    bg_label.image = bg_image  # Maintain a reference to the image object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GENERATE DATASET BUTTON - DATASET WINDOW OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate dataset\n",
    "def generate_dataset():\n",
    "    generate_window = tk.Toplevel(window)\n",
    "    generate_window.title(\"Generate Dataset\")\n",
    "    generate_window.geometry(\"600x400\")  # Set the dimensions of the new window\n",
    "\n",
    "    # Create UI elements for the \"Generate\" page \n",
    "    name_frame = tk.Frame(generate_window)\n",
    "    name_frame.pack(padx=10, pady=10)\n",
    "\n",
    "    entry_name = tk.Entry(name_frame, width=30, font=(\"Helvetica\", 14))\n",
    "    entry_name.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    label_name = tk.Label(name_frame, text=\"Name:\", font=(\"Helvetica\", 14))\n",
    "    label_name.grid(row=0, column=0, padx=5, pady=5)\n",
    "    \n",
    "    num_images_frame = tk.Frame(generate_window)\n",
    "    num_images_frame.pack(padx=10, pady=10)\n",
    "\n",
    "    entry_num_images = tk.Entry(num_images_frame, width=20, font=(\"Helvetica\", 14))  # Set the width to the same value as entry_name\n",
    "    entry_num_images.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "    label_num_images = tk.Label(num_images_frame, text=\"Number of Images:\", font=(\"Helvetica\", 14))\n",
    "    label_num_images.grid(row=0, column=0, padx=5, pady=5)\n",
    "    \n",
    "    button_frame = tk.Frame(generate_window)\n",
    "    button_frame.pack(padx=10, pady=10)\n",
    "\n",
    "    capture_button = tk.Button(button_frame, text=\"Capture Images\", font=(\"Helvetica\", 14), bg=\"green\", fg=\"white\", command=lambda: capture_images(entry_name.get(), entry_num_images.get()))\n",
    "    capture_button.grid(row=1, column=0, columnspan=2, padx=5, pady=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Image - Collecting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of using OpenCV\n",
    "def capture_images_opencv(person_name, num_images):\n",
    "    num_images = int(num_images)  # Convert the value to an integer\n",
    "    print(f\"Person's Name: {person_name}, Number of Images: {num_images}\")\n",
    "\n",
    "    # Set the face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Set the directory for the dataset\n",
    "    dataset_path = 'dataset/'\n",
    "\n",
    "    # Set the path for the person's dataset\n",
    "    person_path = os.path.join(dataset_path, person_name)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(person_path):\n",
    "        os.makedirs(person_path)\n",
    "\n",
    "    # Initialize the camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    image_count = 0\n",
    "\n",
    "    while image_count < num_images:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert the frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect faces\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Draw a rectangle around the face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            # Save the captured face\n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "\n",
    "            # Preprocess the image\n",
    "            resized_face = cv2.resize(face_img, (224, 224))  # Adjust the size based on your model's input size\n",
    "            normalized_face = resized_face / 255.0\n",
    "\n",
    "            # Save the preprocessed image\n",
    "            img_name = f\"img{image_count+1}.jpg\"\n",
    "            img_path = os.path.join(person_path, img_name)\n",
    "            cv2.imwrite(img_path, (normalized_face * 255).astype(\"uint8\"))\n",
    "\n",
    "            image_count += 1\n",
    "\n",
    "            # Display the captured image for a short time\n",
    "            cv2.imshow('Captured Face', face_img)\n",
    "            cv2.waitKey(500)  # Adjust the time in milliseconds (1000 = 1 second)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('Capture Face', frame)\n",
    "\n",
    "        # Break the loop when 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera\n",
    "    cap.release()\n",
    "\n",
    "    # Destroy all OpenCV windows\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "# Function to capture images ---- Upon Clicking the BUTTON\n",
    "def capture_images(person_name, num_images):\n",
    "    capture_images_opencv(person_name, num_images)\n",
    "    messagebox.showinfo(\"Dataset Generation\", f\"{num_images} images captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL BUTTON - TRAINING WINDOW OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global variable for training_window\n",
    "training_window = None\n",
    "\n",
    "# Function to train model\n",
    "def train_model():\n",
    "    global training_window  # Declare training_window as a global variable\n",
    "    training_window = tk.Toplevel(window)\n",
    "    training_window.title(\"Training Options\")\n",
    "    training_window.geometry(\"600x400\")\n",
    "\n",
    "    # Create a button for one-hot encoding\n",
    "    one_hot_button = tk.Button(training_window, text=\"One-Hot Encoding\", font=(\"Helvetica\", 16), bg=\"green\", fg=\"white\", command=perform_one_hot_encoding)\n",
    "    one_hot_button.pack(pady=20)\n",
    "    \n",
    "\n",
    "    # Create a button for CNN model training\n",
    "    train_cnn_button = tk.Button(training_window, text=\"Train CNN Model\", font=(\"Helvetica\", 16), bg=\"#FFA500\", fg=\"black\", command=train_cnn_model)\n",
    "    train_cnn_button.pack(pady=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding &\n",
    "## Data Splitting - Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_27260\\3932030360.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data = np.array(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (600, 2)\n",
      "Label Mapping:\n",
      "Ajay: 0\n",
      "Ananya: 1\n",
      "Isha: 2\n",
      "One-Hot Encoded Labels:\n",
      "Ajay: [1, 0, 0]\n",
      "Ananya: [0, 1, 0]\n",
      "Isha: [0, 0, 1]\n",
      "X_train shape: (480, 224, 224, 3)\n",
      "X_test shape: (120, 224, 224, 3)\n",
      "y_train shape: (480, 3)\n",
      "y_test shape: (120, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Set the directory for the dataset\n",
    "dataset_path = 'dataset/'\n",
    "\n",
    "# Get the list of persons (subdirectories)\n",
    "persons = os.listdir(dataset_path)\n",
    "\n",
    "# Create label mapping for each person\n",
    "label_mapping = {person: idx for idx, person in enumerate(persons)}\n",
    "\n",
    "# Initialize the list to store data and labels\n",
    "data = []\n",
    "\n",
    "# Loop over each person's folder\n",
    "for person in persons:\n",
    "    person_directory = os.path.join(dataset_path, person)\n",
    "\n",
    "    # Get the label for the person\n",
    "    label = [0] * len(persons)\n",
    "    label[label_mapping[person]] = 1\n",
    "\n",
    "    # Loop over each image in the person's folder\n",
    "    for img_name in os.listdir(person_directory):\n",
    "        img_path = os.path.join(person_directory, img_name)\n",
    "\n",
    "        # Read the image \n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # preprocessing\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        normalized_img = resized_img / 255.0\n",
    "\n",
    "        # Append the preprocessed image and label to the list\n",
    "        data.append([img, label])\n",
    "\n",
    "# Convert the list to a NumPy array\n",
    "data = np.array(data)\n",
    "\n",
    "# Shuffle the data\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Print the shape of the data\n",
    "print(\"Shape of data:\", data.shape)\n",
    "\n",
    "# Save the data to a file (if needed)\n",
    "np.save('data.npy', data)\n",
    "\n",
    "\n",
    "print(\"Label Mapping:\")\n",
    "for person, label in label_mapping.items():\n",
    "    print(f\"{person}: {label}\")\n",
    "\n",
    "\n",
    "print(\"One-Hot Encoded Labels:\")\n",
    "for person, label in label_mapping.items():\n",
    "    one_hot_encoded = [0] * len(label_mapping)\n",
    "    one_hot_encoded[label] = 1\n",
    "    print(f\"{person}: {one_hot_encoded}\")\n",
    "\n",
    "\n",
    "\n",
    "# Assuming 'data' contains both images and labels\n",
    "X = np.array([item[0] for item in data])\n",
    "y = np.array([item[1] for item in data])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shape of the sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_to_message_box(message):\n",
    "    messagebox.showinfo(\"Information\", message)  # Display message in a messagebox\n",
    "\n",
    "\n",
    "# Function to perform one-hot encoding\n",
    "\n",
    "def perform_one_hot_encoding():\n",
    "    # Set the directory for the dataset\n",
    "    dataset_path = 'dataset/'\n",
    "\n",
    "    # Get the list of persons (subdirectories)\n",
    "    persons = os.listdir(dataset_path)\n",
    "\n",
    "    # Create label mapping for each person\n",
    "    label_mapping = {person: idx for idx, person in enumerate(persons)}\n",
    "\n",
    "    # Initialize the list to store data and labels\n",
    "    data = []\n",
    "\n",
    "    # Loop over each person's folder\n",
    "    for person in persons:\n",
    "        person_directory = os.path.join(dataset_path, person)\n",
    "\n",
    "        # Get the label for the person\n",
    "        label = [0] * len(persons)\n",
    "        label[label_mapping[person]] = 1\n",
    "\n",
    "        # Loop over each image in the person's folder\n",
    "        for img_name in os.listdir(person_directory):\n",
    "            img_path = os.path.join(person_directory, img_name)\n",
    "\n",
    "            # Read the image \n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # Preprocessing\n",
    "            resized_img = cv2.resize(img, (224, 224))\n",
    "            normalized_img = resized_img / 255.0\n",
    "\n",
    "            # Append the preprocessed image and label to the list\n",
    "            data.append([img, label])\n",
    "\n",
    "    # Convert the list to a NumPy array\n",
    "    data = np.array(data)\n",
    "\n",
    "    # Shuffle the data\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    # ...\n",
    "\n",
    "    \n",
    "    message = f\"Shape of data: {data.shape}\"\n",
    "    print_to_message_box(message)\n",
    "\n",
    "    # Save the data to a file (if needed)\n",
    "    np.save('data.npy', data)\n",
    "\n",
    "    \n",
    "    label_mapping_str = \"\\nLabel Mapping:\\n\"\n",
    "    for person, label in label_mapping.items():\n",
    "        label_mapping_str += f\"{person}: {label}\\n\"\n",
    "    print_to_message_box(label_mapping_str)\n",
    "\n",
    "\n",
    "    \n",
    "    one_hot_encoded_str = \"\\nOne-Hot Encoded Labels:\\n\"\n",
    "    for person, label in label_mapping.items():\n",
    "        one_hot_encoded = [0] * len(label_mapping)\n",
    "        one_hot_encoded[label] = 1\n",
    "        one_hot_encoded_str += f\"{person}: {one_hot_encoded}\\n\"\n",
    "    print_to_message_box(one_hot_encoded_str)    \n",
    "\n",
    "    # Assuming 'data' contains both images and labels\n",
    "    X = np.array([item[0] for item in data])\n",
    "    y = np.array([item[1] for item in data])\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    training_info = \"\\nTraining Information:\\n\"\n",
    "    training_info += \"X_train shape: \" + str(X_train.shape) + \"\\n\"\n",
    "    training_info += \"X_test shape: \" + str(X_test.shape) + \"\\n\"\n",
    "    training_info += \"y_train shape: \" + str(y_train.shape) + \"\\n\"\n",
    "    training_info += \"y_test shape: \" + str(y_test.shape) + \"\\n\"\n",
    "    print_to_message_box(training_info)    \n",
    "\n",
    "    \n",
    "    global training_window\n",
    "    training_window.destroy()  # Close the training options window\n",
    "    messagebox.showinfo(\"One-Hot Encoding\", \"One-hot encoding completed\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_subfolders(dataset_path):\n",
    "    if not os.path.exists(dataset_path):\n",
    "        return 0\n",
    "\n",
    "    subfolders = [f for f in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, f))]\n",
    "    return len(subfolders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # Define the CNN model\n",
    "# model = Sequential()\n",
    "\n",
    "# # Default parameters\n",
    "# num_conv_layers = 1  # Number of convolutional layers\n",
    "# num_filters = 32  # Number of filters for the first convolutional layer\n",
    "# dropout_rate = 0.5  # Dropout rate\n",
    "# num_output_neurons = 5  # Number of output neurons / number of classes\n",
    "# num_fc_neurons = 128  # Number of neurons in the fully connected layer\n",
    "# num_epochs = 2\n",
    "\n",
    "# # Get the number of subfolders in the dataset directory\n",
    "# dataset_path = 'dataset/'\n",
    "# num_output_neurons = count_subfolders(dataset_path)\n",
    "\n",
    "# # print(\"Number of Output Neurons:\", num_output_neurons)\n",
    "\n",
    "# model.add(Conv2D(num_filters, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# for _ in range(num_conv_layers - 1):  # Add extra convolutional layers based on user input\n",
    "#     num_filters *= 2  # Double the number of filters with each layer\n",
    "#     model.add(Conv2D(num_filters, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(num_fc_neurons, activation='relu'))\n",
    "# model.add(Dropout(dropout_rate))\n",
    "# model.add(Dense(num_output_neurons, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# # Function to convert one-hot encoded labels to class labels\n",
    "# def one_hot_to_label(one_hot):\n",
    "#     if len(one_hot.shape) > 1:\n",
    "#         return np.argmax(one_hot, axis=1)\n",
    "#     else:\n",
    "#         return int(one_hot[0])  # Extract the single value from the array\n",
    "\n",
    "# # Function to display random images from the test set with true and predicted labels\n",
    "# def visualize_predictions(X_test, y_true, y_pred):\n",
    "#     num_samples_to_display = 5\n",
    "#     random_indices = random.sample(range(len(X_test)), num_samples_to_display)\n",
    "\n",
    "#     for idx in random_indices:\n",
    "#         # Display the image\n",
    "#         plt.imshow(X_test[idx])\n",
    "#         plt.title(f\"True: {one_hot_to_label(y_true[idx])}, Predicted: {y_pred[idx]}\")\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "\n",
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # Convert one-hot encoded true labels to class labels\n",
    "# y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# # Convert one-hot encoded predictions to class labels\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# # Print true and predicted labels for a few samples\n",
    "# for i in range(10):  # Adjust the range based on the number of samples you want to inspect\n",
    "#     print(f\"Sample {i + 1}: True Label = {y_true_classes[i]}, Predicted Label = {y_pred_classes[i]}\")\n",
    "\n",
    "# # Visualize predictions\n",
    "# visualize_predictions(X_test, y_test, y_pred_classes)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# Function to train CNN model\n",
    "def train_cnn_model():\n",
    "    \n",
    "    # Default parameters\n",
    "    num_conv_layers = 1  # Number of convolutional layers\n",
    "    num_filters = 32  # Number of filters for the first convolutional layer\n",
    "    dropout_rate = 0.5  # Dropout rate\n",
    "    num_output_neurons = 4  # Number of output neurons (adjust based on the number of classes)\n",
    "    num_fc_neurons = 128  # Number of neurons in the fully connected layer\n",
    "    num_epochs = 1\n",
    "    \n",
    "    # User Defined Parameters\n",
    "    # ...  \n",
    "    \n",
    "    # Get the number of subfolders in the dataset directory\n",
    "    dataset_path = 'dataset/'\n",
    "    num_output_neurons = count_subfolders(dataset_path)\n",
    "\n",
    "    # print(\"Number of Output Neurons:\", num_output_neurons)\n",
    "\n",
    "\n",
    "    model.add(Conv2D(num_filters, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    for _ in range(num_conv_layers - 1):  # Add extra convolutional layers based on user input\n",
    "        num_filters *= 2  # Double the number of filters with each layer\n",
    "        model.add(Conv2D(num_filters, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_fc_neurons, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_output_neurons, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "\n",
    "    global training_window\n",
    "    training_window.destroy()  # Close the training options window\n",
    "    messagebox.showinfo(\"Model Training\", \"Model training completed\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT / DETECT BUTTON - PREDICTION WINDOW OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect faces\n",
    "def detect_faces():\n",
    "    detect_window = tk.Toplevel(window)\n",
    "    detect_window.title(\"Face Detection/Prediction\")\n",
    "\n",
    "    camera_button = tk.Button(detect_window, text=\"Open Camera\", font=(\"Helvetica\", 14), bg=\"blue\", fg=\"white\", command=open_camera_detection)\n",
    "    camera_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "    image_button = tk.Button(detect_window, text=\"Select Image\", font=(\"Helvetica\", 14), bg=\"purple\", fg=\"white\", command=select_image_detection)\n",
    "    image_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "    random_button = tk.Button(detect_window, text=\"Random Dataset\", font=(\"Helvetica\", 14), bg=\"orange\", fg=\"white\", command=random_dataset_window)\n",
    "    random_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "# Function to open camera and detect faces\n",
    "def open_camera_detection():\n",
    "    # Add code for opening the camera and detecting faces\n",
    "    pass\n",
    "\n",
    "# Function to select an image and detect faces\n",
    "def select_image_detection():\n",
    "    # Add code for selecting an image from the computer and detecting faces\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Random Dataset Prediction WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open a new window for random dataset detection\n",
    "def random_dataset_window():\n",
    "    # Create a new window for random dataset detection\n",
    "    random_window = tk.Toplevel(window)\n",
    "    random_window.title(\"Random Dataset Detection\")\n",
    "    \n",
    "    # Set the size of the new window\n",
    "    random_window.geometry('400x250')\n",
    "    \n",
    "    # Create a label to instruct the user\n",
    "    label = tk.Label(random_window, text=\"Enter the number of random images to select:\", font=(\"Helvetica\", 14))\n",
    "    label.pack(pady=10)\n",
    "    \n",
    "    # Create an Entry widget to take user input\n",
    "    entry = tk.Entry(random_window, font=(\"Helvetica\", 14))\n",
    "    entry.pack()\n",
    "    \n",
    "    # Create a button to trigger random dataset detection with the specified number\n",
    "    detect_button = tk.Button(random_window, text=\"Detect Random Images\", font=(\"Helvetica\", 14), bg=\"green\", fg=\"white\", command=lambda: detect_random_images(entry.get()))\n",
    "    detect_button.pack(pady=10)\n",
    "\n",
    "# Function to detect random images based on the user's input\n",
    "def detect_random_images(num_images):\n",
    "    try:\n",
    "        num_images = int(num_images)\n",
    "        # Call the function to perform predictions\n",
    "        random_dataset_detection(model, dataset_path, label_mapping, num_images)\n",
    "        \n",
    "    except ValueError:\n",
    "        # Handle the case where the user enters a non-integer value\n",
    "        error_message = \"Please enter a valid integer for the number of images.\"\n",
    "        messagebox.showerror(\"Error\", error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function - Prediction from Random Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform predictions on random images from the dataset\n",
    "def random_dataset_detection(model, dataset_path, label_mapping, num_images):\n",
    "    # Get the list of persons (subdirectories)\n",
    "    persons = os.listdir(dataset_path)\n",
    "\n",
    "    # Initialize lists to store random images and labels\n",
    "    random_images = []\n",
    "    random_labels = []\n",
    "\n",
    "    num_samples_to_predict = num_images  # Adjust the number of samples to predict\n",
    "\n",
    "    for _ in range(num_samples_to_predict):\n",
    "        # Choose a random person from the dataset\n",
    "        random_person = random.choice(persons)\n",
    "        person_directory = os.path.join(dataset_path, random_person)\n",
    "\n",
    "        # Choose a random image from the person's folder\n",
    "        random_image_name = random.choice(os.listdir(person_directory))\n",
    "        img_path = os.path.join(person_directory, random_image_name)\n",
    "\n",
    "        # Read and preprocess the random image\n",
    "        img = cv2.imread(img_path)\n",
    "        resized_img = cv2.resize(img, (224, 224))\n",
    "        normalized_img = resized_img / 255.0\n",
    "\n",
    "        # Append the preprocessed image to the list\n",
    "        random_images.append(normalized_img)\n",
    "\n",
    "        # Get the label for the person\n",
    "        label = [0] * len(label_mapping)\n",
    "        label[label_mapping[random_person]] = 1\n",
    "        random_labels.append(label)\n",
    "\n",
    "    # Convert the list of random images to a NumPy array\n",
    "    random_images = np.array(random_images)\n",
    "\n",
    "    # Make predictions on the random images\n",
    "    predictions = model.predict(random_images)\n",
    "\n",
    "    # Convert one-hot encoded predictions to class labels\n",
    "    predicted_classes = [np.argmax(prediction) for prediction in predictions]\n",
    "\n",
    "    # Display random images and their predicted labels\n",
    "    for i in range(num_samples_to_predict):\n",
    "        plt.imshow(random_images[i])\n",
    "        true_label = [person for person, label in label_mapping.items() if random_labels[i][label] == 1][0]\n",
    "        predicted_label = [person for person, label in label_mapping.items() if predicted_classes[i] == label][0]\n",
    "        plt.title(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN WINDOW - HOME PAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Facial Recognition System\")\n",
    "\n",
    "# Create a label for the background image\n",
    "bg_label = tk.Label(window)\n",
    "bg_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "# Bind the set_background_image function to the window's Configure event\n",
    "window.bind(\"<Configure>\", set_background_image)\n",
    "\n",
    "\n",
    "title_label = tk.Label(window, text=\"Facial Recognition System\", font=(\"Helvetica\", 35), bg=\"#00020E\", fg=\"white\")\n",
    "title_label.pack(pady=20)\n",
    "\n",
    "frame = tk.Frame(window, bg=\"#021E2C\")\n",
    "frame.pack(side=\"bottom\", pady=0)\n",
    "\n",
    "generate_button = tk.Button(frame, text=\"Generate Dataset\", font=(\"Helvetica\", 16), bg=\"green\", fg=\"white\", command=generate_dataset)\n",
    "generate_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "train_button = tk.Button(frame, text=\"Train Model\", font=(\"Helvetica\", 16), bg=\"yellow\", fg=\"black\", command=train_model)\n",
    "train_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "detect_button = tk.Button(frame, text=\"Detect / Predict\", font=(\"Helvetica\", 16), bg=\"purple\", fg=\"white\", command=detect_faces)\n",
    "detect_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "window.geometry(\"900x600\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tkinter as tk\n",
    "# from tkinter import filedialog\n",
    "# from tkinter import messagebox\n",
    "# from PIL import Image, ImageTk\n",
    "\n",
    "# # Function to set the background image\n",
    "# def set_background_image(event=None):\n",
    "#     # Get the current window size\n",
    "#     window_width = window.winfo_width()\n",
    "#     window_height = window.winfo_height()\n",
    "\n",
    "#     # Load the image and resize it to fit the window\n",
    "#     bg_image = Image.open(\"bgimg.jpg\")  # Replace with your image file\n",
    "#     bg_image = bg_image.resize((window_width, window_height), Image.LANCZOS)\n",
    "#     bg_image = ImageTk.PhotoImage(bg_image)\n",
    "\n",
    "#     bg_label.configure(image=bg_image)\n",
    "#     bg_label.image = bg_image  # Maintain a reference to the image object\n",
    "\n",
    "# # Function to generate dataset\n",
    "# def generate_dataset():\n",
    "#     generate_window = tk.Toplevel(window)\n",
    "#     generate_window.title(\"Generate Dataset\")\n",
    "\n",
    "#     set_background_image(generate_window)  # Call the function to set the background image\n",
    "\n",
    "#     # Create UI elements for the \"Generate\" page (similar to the home page)\n",
    "#     name_frame = tk.Frame(generate_window)\n",
    "#     name_frame.pack(padx=10, pady=10)\n",
    "\n",
    "#     entry_name = tk.Entry(name_frame, width=30, font=(\"Helvetica\", 14))\n",
    "#     entry_name.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "#     label_name = tk.Label(name_frame, text=\"Name:\", font=(\"Helvetica\", 14))\n",
    "#     label_name.grid(row=0, column=0, padx=5, pady=5)\n",
    "\n",
    "#     capture_button = tk.Button(name_frame, text=\"Capture Images\", font=(\"Helvetica\", 14), bg=\"green\", fg=\"white\", command=capture_images)\n",
    "#     capture_button.grid(row=1, column=0, columnspan=2, padx=5, pady=10)\n",
    "\n",
    "# # Function to capture images\n",
    "# def capture_images():\n",
    "#     # Capture 500 images for the given name\n",
    "#     # Implement this functionality with a camera\n",
    "#     messagebox.showinfo(\"Dataset Generation\", \"Images captured\")\n",
    "\n",
    "# # Function to train model\n",
    "# def train_model():\n",
    "#     # Add code to train your CNN model\n",
    "#     messagebox.showinfo(\"Model Training\", \"Model training completed\")\n",
    "\n",
    "# # Function to detect faces\n",
    "# def detect_faces():\n",
    "#     detect_window = tk.Toplevel(window)\n",
    "#     detect_window.title(\"Face Detection/Prediction\")\n",
    "\n",
    "#     camera_button = tk.Button(detect_window, text=\"Open Camera\", font=(\"Helvetica\", 14), bg=\"blue\", fg=\"white\", command=open_camera_detection)\n",
    "#     camera_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "#     image_button = tk.Button(detect_window, text=\"Select Image\", font=(\"Helvetica\", 14), bg=\"purple\", fg=\"white\", command=select_image_detection)\n",
    "#     image_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "#     random_button = tk.Button(detect_window, text=\"Random Dataset\", font=(\"Helvetica\", 14), bg=\"orange\", fg=\"white\", command=random_dataset_detection)\n",
    "#     random_button.pack(side=\"left\", padx=5, pady=10)\n",
    "\n",
    "# # Function to open camera and detect faces\n",
    "# def open_camera_detection():\n",
    "#     # Add code for opening the camera and detecting faces\n",
    "#     pass\n",
    "\n",
    "# # Function to select an image and detect faces\n",
    "# def select_image_detection():\n",
    "#     # Add code for selecting an image from the computer and detecting faces\n",
    "#     pass\n",
    "\n",
    "# # Function to take random images from the dataset and perform prediction\n",
    "# def random_dataset_detection():\n",
    "#     # Add code to take random images from the dataset and perform prediction\n",
    "#     pass\n",
    "\n",
    "# # Main window\n",
    "# window = tk.Tk()\n",
    "# window.title(\"Facial Recognition System\")\n",
    "\n",
    "# # Create a label for the background image\n",
    "# bg_label = tk.Label(window)\n",
    "# bg_label.place(relwidth=1, relheight=1)\n",
    "\n",
    "# # Bind the set_background_image function to the window's Configure event\n",
    "# window.bind(\"<Configure>\", set_background_image)\n",
    "\n",
    "# title_label = tk.Label(window, text=\"Facial Recognition System\", font=(\"Helvetica\", 35), bg=\"#00020E\", fg=\"white\")\n",
    "# title_label.pack(pady=20)\n",
    "\n",
    "# frame = tk.Frame(window, bg=\"#021E2C\")\n",
    "# frame.pack(side=\"bottom\", pady=0)\n",
    "\n",
    "# generate_button = tk.Button(frame, text=\"Generate Dataset\", font=(\"Helvetica\", 16), bg=\"green\", fg=\"white\", command=generate_dataset)\n",
    "# generate_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "# train_button = tk.Button(frame, text=\"Train Model\", font=(\"Helvetica\", 16), bg=\"#FFA500\", fg=\"black\", command=train_model)\n",
    "# train_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "# detect_button = tk.Button(frame, text=\"Detect / Predict\", font=(\"Helvetica\", 16), bg=\"purple\", fg=\"white\", command=detect_faces)\n",
    "# detect_button.pack(side=\"left\", padx=15, pady=25)\n",
    "\n",
    "# window.geometry(\"900x600\")\n",
    "# window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
